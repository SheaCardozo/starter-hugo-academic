---
title: Transformer Circuits; Decomposing Small Language Models
subtitle: Can we understand what's going in Large Language Models by dissecting small ones?

# Summary for listings and search engines
summary: An adaptation of Anthropic AI's paper 'A Mathematical Framework for Transformer Circuits'.

# Link this post with a project
projects: []

# Date published
date: '2022-12-17T20:00:00Z'

# Date updated
lastmod: '2022-12-17T20:00:00Z'

# Is this an unpublished draft?
draft: false

# Show this page in the Featured widget?
featured: true

# Featured image
# Place an image named `featured.jpg/png` in this page's folder and customize its options here.
image:
  caption: 'Robots in disguise'
  focal_point: ''
  placement: 2
  preview_only: false

authors:
  - admin
---

This post is available [here](https://medium.com/@sheacardozo/transformer-circuits-decomposing-small-language-models-10f05c61dfd5).